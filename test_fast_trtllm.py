#!/usr/bin/env python3
"""
TensorRT-LLM æ¨ç†è´¨é‡æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¿®å¤åçš„ TensorRT-LLM é›†æˆæ˜¯å¦èƒ½æ­£ç¡®ç”Ÿæˆä¸è¾“å…¥æ–‡æœ¬åŒ¹é…çš„éŸ³é¢‘
"""

import sys
import os
import torch
import time
import numpy as np

sys.path.append("third_party/Matcha-TTS")

def test_trtllm_quality():
    """æµ‹è¯• TensorRT-LLM æ¨ç†è´¨é‡"""
    print("=" * 60)
    print("ğŸ“ TensorRT-LLM æ¨ç†è´¨é‡æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥ TensorRT-LLM æ˜¯å¦å¯ç”¨
    try:
        import tensorrt_llm
        from tensorrt_llm.runtime import ModelRunnerCpp
        print(f"âœ… TensorRT-LLM ç‰ˆæœ¬: {tensorrt_llm.__version__}")
        trtllm_available = True
    except ImportError as e:
        print(f"âŒ TensorRT-LLM ä¸å¯ç”¨: {e}")
        trtllm_available = False
        return
    
    # æ£€æŸ¥å¼•æ“
    engine_path = "runtime/triton_trtllm/trt_engines_bfloat16/rank0.engine"
    engine_dir = "runtime/triton_trtllm/trt_engines_bfloat16"
    
    # Tokenizer ç›®å½•
    tokenizer_dir = "runtime/triton_trtllm/cosyvoice2_llm"
    if not os.path.exists(tokenizer_dir):
        # å°è¯•å¤‡ç”¨è·¯å¾„
        alt_tokenizer_dir = "pretrained_models/CosyVoice2-0.5B/CosyVoice-BlankEN"
        if os.path.exists(alt_tokenizer_dir):
            tokenizer_dir = alt_tokenizer_dir
            print(f"ğŸ“¡ ä½¿ç”¨å¤‡ç”¨ tokenizer: {tokenizer_dir}")
        else:
            print(f"âŒ Tokenizer ç›®å½•ä¸å­˜åœ¨: {tokenizer_dir}")
            return
    
    if os.path.exists(engine_path):
        size_mb = os.path.getsize(engine_path) / (1024 * 1024)
        print(f"âœ… å¼•æ“å­˜åœ¨: {size_mb:.2f} MB")
    else:
        print(f"âŒ å¼•æ“ä¸å­˜åœ¨: {engine_path}")
        return
    
    # åŠ è½½æ¨¡å‹
    print("\nåŠ è½½ CosyVoice2 æ¨¡å‹...")
    from cosyvoice.cli.cosyvoice import CosyVoice2
    cosyvoice = CosyVoice2("pretrained_models/CosyVoice2-0.5B", load_jit=True, load_trt=True, fp16=True)
    print("âœ… CosyVoice2 åŠ è½½æˆåŠŸ")
    
    # åŠ è½½ FastCosyVoice2
    print("\nåˆå§‹åŒ– FastCosyVoice2 (TensorRT-LLM æ¨¡å¼)...")
    from fast_server import FastCosyVoice2
    
    fast_cosyvoice = FastCosyVoice2(
        cosyvoice_model=cosyvoice,
        trtllm_engine_dir=engine_dir,
        trtllm_tokenizer_dir=tokenizer_dir,
        use_trtllm=True
    )
    
    if fast_cosyvoice.use_trtllm:
        print("âœ… FastCosyVoice2 åˆå§‹åŒ–æˆåŠŸ (TensorRT-LLM)")
    else:
        print("âŒ FastCosyVoice2 TensorRT-LLM åˆå§‹åŒ–å¤±è´¥")
        return
    
    # åŠ è½½è¯´è¯äºº
    print("\nåŠ è½½è¯´è¯äºº...")
    from cosyvoice.utils.file_utils import load_wav
    import glob
    import re
    
    wav_files = glob.glob("asset/speakers/*.wav")
    if not wav_files:
        print("âŒ æœªæ‰¾åˆ°è¯´è¯äººæ–‡ä»¶")
        return
    
    test_wav = wav_files[0]
    filename = os.path.basename(test_wav)
    match = re.match(r'\[(.+?)\](.+)\.wav$', filename)
    
    if not match:
        print(f"âŒ æ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®: {filename}")
        return
    
    speaker_name = match.group(1)
    prompt_text = match.group(2)
    
    print(f"åŠ è½½è¯´è¯äºº: {speaker_name}")
    print(f"Prompt æ–‡æœ¬: {prompt_text[:50]}...")
    
    prompt_speech_16k = load_wav(test_wav, 16000)
    
    # å½’ä¸€åŒ–
    max_val = torch.abs(prompt_speech_16k).max().item()
    if max_val > 0.95:
        prompt_speech_16k = (prompt_speech_16k / max_val) * 0.95
    
    fast_cosyvoice.add_zero_shot_spk(prompt_text, prompt_speech_16k, speaker_name)
    print(f"âœ… è¯´è¯äººæ·»åŠ æˆåŠŸ: {speaker_name}")
    
    # æµ‹è¯•æ¨ç†
    print("\n" + "=" * 60)
    print("ğŸ¯ æµ‹è¯•æ¨ç† (TensorRT-LLM æ¨¡å¼)")
    print("=" * 60)
    
    test_texts = [
        "ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨è¿™ä¸ªè¯­éŸ³åˆæˆç³»ç»Ÿï¼",
        "ä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œé€‚åˆå‡ºå»èµ°èµ°ã€‚",
        "æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œå¾ˆæ„ŸåŠ¨ã€‚",
    ]
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "output_test_trtllm"
    os.makedirs(output_dir, exist_ok=True)
    
    import soundfile as sf
    
    for i, test_text in enumerate(test_texts):
        print(f"\næµ‹è¯• {i+1}/{len(test_texts)}: {test_text}")
        print("-" * 40)
        
        start_time = time.time()
        audio_chunks = []
        
        try:
            for output in fast_cosyvoice.inference_zero_shot(
                test_text, "", None,
                zero_shot_spk_id=speaker_name,
                stream=True
            ):
                audio_chunks.append(output['tts_speech'].numpy())
            
            if audio_chunks:
                full_audio = np.concatenate(audio_chunks, axis=1).flatten()
                duration = len(full_audio) / 24000
                total_time = time.time() - start_time
                
                # ä¿å­˜éŸ³é¢‘
                output_path = os.path.join(output_dir, f"test_{i+1}.wav")
                sf.write(output_path, full_audio, 24000)
                
                print(f"âœ… ç”ŸæˆæˆåŠŸ!")
                print(f"   éŸ³é¢‘æ—¶é•¿: {duration:.2f}s")
                print(f"   æ¨ç†æ—¶é—´: {total_time:.2f}s")
                print(f"   RTF: {total_time/duration:.2f}x")
                print(f"   è¾“å‡º: {output_path}")
            else:
                print("âŒ æœªç”Ÿæˆä»»ä½•éŸ³é¢‘")
                
        except Exception as e:
            print(f"âŒ æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶ä¿å­˜åœ¨: {output_dir}/")
    print("ğŸ§ è¯·æ’­æ”¾éŸ³é¢‘æ–‡ä»¶æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸è¾“å…¥æ–‡æœ¬åŒ¹é…")
    print("=" * 60)


if __name__ == "__main__":
    test_trtllm_quality()
