#!/usr/bin/env python3
"""
MVP æµå¼æœåŠ¡æµ‹è¯•è„šæœ¬
ç”¨äºæ’æŸ¥éŸ³é¢‘ç”Ÿæˆé—®é¢˜ï¼š
1. æç¤ºéŸ³é¢‘æ³„éœ²ï¼ˆç”Ÿæˆçš„éŸ³é¢‘åŒ…å«æç¤ºéŸ³é¢‘å†…å®¹ï¼‰
2. éŸ³è°ƒå¼‚å¸¸ï¼ˆæç¤ºè¯éƒ¨åˆ†éŸ³è°ƒä¸æ­£å¸¸ï¼‰
"""
import sys
sys.path.append('third_party/Matcha-TTS')
import os
import time
import torch
import torchaudio
import argparse
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s.%(msecs)03d %(levelname)s %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# Monkey patch load_wav å‡½æ•°ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ CosyVoice ä¹‹å‰ï¼‰
import cosyvoice.utils.file_utils

def patched_load_wav(wav, target_sr, min_sr=16000):
    """ä½¿ç”¨ soundfile æ›¿ä»£ torchaudio.load ä»¥å…¼å®¹ PyTorch 2.9.x"""
    import soundfile as sf
    speech, sample_rate = sf.read(wav, dtype='float32')
    if len(speech.shape) == 1:
        speech = torch.from_numpy(speech).unsqueeze(0)
    else:
        speech = torch.from_numpy(speech).T
    speech = speech.mean(dim=0, keepdim=True)
    if sample_rate != target_sr:
        assert sample_rate >= min_sr, f'wav sample rate {sample_rate} must be greater than {target_sr}'
        speech = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sr)(speech)
    return speech

cosyvoice.utils.file_utils.load_wav = patched_load_wav

# å¯¼å…¥ vLLM å’Œ CosyVoice
from vllm import ModelRegistry
from cosyvoice.vllm.cosyvoice3 import CosyVoice3ForCausalLM
from cosyvoice.cli.cosyvoice import AutoModel

# æ³¨å†Œæ¨¡å‹
ModelRegistry.register_model("CosyVoice3ForCausalLM", CosyVoice3ForCausalLM)


def save_audio(audio_tensor, sample_rate, filename):
    """ä¿å­˜éŸ³é¢‘æ–‡ä»¶"""
    import soundfile as sf
    audio_data = audio_tensor.squeeze().cpu().numpy()
    sf.write(filename, audio_data, sample_rate)
    logging.info(f"âœ“ ä¿å­˜éŸ³é¢‘: {filename} ({audio_data.shape[0] / sample_rate:.2f}s)")


def test_case_4_streaming_chunks(cosyvoice, test_text, prompt_text, prompt_wav, spk_id='test_speaker_stream'):
    """
    æµ‹è¯•ç”¨ä¾‹ 4: æµå¼æ¨ç†ï¼ˆæ£€æŸ¥æ¯ä¸ªéŸ³é¢‘å—çš„è´¨é‡ï¼‰
    """
    logging.info("=" * 70)
    logging.info(f"æµ‹è¯•ç”¨ä¾‹ 4: æµå¼æ¨ç†ï¼ˆæ£€æŸ¥æ¯ä¸ªéŸ³é¢‘å—ï¼‰")
    logging.info("=" * 70)
    
    # å…ˆæ³¨å†Œè¯´è¯äºº
    logging.info(f"æ³¨å†Œè¯´è¯äºº: {spk_id}")
    cosyvoice.add_zero_shot_spk(prompt_text, prompt_wav, spk_id)
    
    # æµå¼æ¨ç†
    logging.info(f"ä½¿ç”¨ zero_shot_spk_id='{spk_id}' è¿›è¡Œæµå¼æ¨ç†...")
    output_chunks = []
    chunk_count = 0
    
    for i, output in enumerate(cosyvoice.inference_zero_shot(
        test_text,
        '',
        None,
        zero_shot_spk_id=spk_id,
        stream=True  # å¯ç”¨æµå¼
    )):
        chunk_audio = output['tts_speech']
        chunk_duration = chunk_audio.shape[1] / cosyvoice.sample_rate
        logging.info(f"  éŸ³é¢‘å— {chunk_count}: {chunk_duration*1000:.1f}ms ({chunk_audio.shape[1]} samples)")
        
        # ä¿å­˜æ¯ä¸ªéŸ³é¢‘å—
        save_audio(chunk_audio, cosyvoice.sample_rate, f'test_case4_chunk_{chunk_count:02d}.wav')
        output_chunks.append(chunk_audio)
        chunk_count += 1
    
    # æ‹¼æ¥æ‰€æœ‰éŸ³é¢‘å—
    if output_chunks:
        full_audio = torch.cat(output_chunks, dim=1)
        save_audio(full_audio, cosyvoice.sample_rate, 'test_case4_streaming_full.wav')
        logging.info(f"æµå¼æ¨ç†å®Œæˆï¼Œå…± {chunk_count} ä¸ªéŸ³é¢‘å—")
    
    logging.info("âœ“ æµ‹è¯•ç”¨ä¾‹ 4 å®Œæˆ\n")


def main():
    parser = argparse.ArgumentParser(description='MVP æµå¼æœåŠ¡æµ‹è¯•è„šæœ¬')
    parser.add_argument(
        '--model_dir',
        type=str,
        default='/home/cz/ai/CosyVoice/pretrained_models/Fun-CosyVoice3-0.5B',
        help='æ¨¡å‹ç›®å½•ï¼ˆç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„ï¼‰'
    )
    parser.add_argument(
        '--test_text',
        type=str,
        default=' å“¼ï¼Œä½ è¿˜çŸ¥é“å›æ¥å‘€ï¼Ÿé¥­èœéƒ½å‡‰é€äº†ï¼ ',
        help='æµ‹è¯•æ–‡æœ¬'
    )
    parser.add_argument(
        '--prompt_text',
        type=str,
        default='You are a helpful assistant.<|endofprompt|>è¯´å¾—å¥½åƒæ‚¨å¸¦æˆ‘ä»¥æ¥æˆ‘è€ƒå¥½è¿‡å‡ æ¬¡ä¸€æ ·ã€‚',
        help='æç¤ºæ–‡æœ¬'
    )
    parser.add_argument(
        '--prompt_wav',
        type=str,
        default='/home/cz/ai/CosyVoice/asset/speakers/[jokè€å¸ˆ]è¯´å¾—å¥½åƒæ‚¨å¸¦æˆ‘ä»¥æ¥æˆ‘è€ƒå¥½è¿‡å‡ æ¬¡ä¸€æ ·.wav',
        help='æç¤ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„ï¼‰'
    )
    parser.add_argument(
        '--output_dir',
        type=str,
        default='./test_output',
        help='è¾“å‡ºç›®å½•'
    )
    args = parser.parse_args()
    
    # è½¬æ¢ç›¸å¯¹è·¯å¾„ä¸ºç»å¯¹è·¯å¾„
    import os
    if not os.path.isabs(args.model_dir):
        args.model_dir = os.path.abspath(args.model_dir)
    if not os.path.isabs(args.prompt_wav):
        args.prompt_wav = os.path.abspath(args.prompt_wav)
    if not os.path.isabs(args.output_dir):
        args.output_dir = os.path.abspath(args.output_dir)
    
    logging.info(f"æ¨¡å‹ç›®å½•: {args.model_dir}")
    logging.info(f"æç¤ºéŸ³é¢‘: {args.prompt_wav}")
    logging.info(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    os.chdir(args.output_dir)
    
    # åŠ è½½æ¨¡å‹
    logging.info("=" * 70)
    logging.info("å¼€å§‹åŠ è½½ CosyVoice3 æ¨¡å‹ï¼ˆvLLM 0.12.0ï¼‰")
    logging.info("=" * 70)
    
    cosyvoice = AutoModel(
        model_dir=args.model_dir,
        load_trt=True,
        load_vllm=True,
        fp16=False
    )
    
    logging.info("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ\n")
    
    # è¿è¡Œæµ‹è¯•ç”¨ä¾‹
    logging.info("ğŸ” å¼€å§‹è¿è¡Œæµ‹è¯•ç”¨ä¾‹...")
    logging.info("")
    
    # æµ‹è¯•ç”¨ä¾‹ 4: æµå¼æ¨ç†
    test_case_4_streaming_chunks(
        cosyvoice,
        args.test_text,
        args.prompt_text,
        args.prompt_wav,
        spk_id='test_speaker_stream'
    )

    logging.info("=" * 70)
    logging.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹å®Œæˆï¼")
    logging.info(f"è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨: {os.getcwd()}")
    logging.info("=" * 70)
    logging.info("")


if __name__ == '__main__':
    main()
