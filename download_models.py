#!/usr/bin/env python3
"""
CosyVoice æ¨¡å‹ä¸‹è½½è„šæœ¬

ä½¿ç”¨æ–¹æ³•ï¼š
  python download_models.py                    # ä¸‹è½½æ¨èæ¨¡å‹ (2.0, 2.0-llm, tts)
  python download_models.py --model 2.0        # ä»…ä¸‹è½½ CosyVoice 2.0 (ModelScope)
  python download_models.py --model 2.0-llm    # ä»…ä¸‹è½½ CosyVoice 2.0 LLM (HuggingFace)
  python download_models.py --model 300m       # ä»…ä¸‹è½½ CosyVoice-300M
  python download_models.py --list             # åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹

ğŸ’¡ ç¦»çº¿ä¸‹è½½æ”¯æŒï¼š
  - ä¸€æ—¦ç½‘ç»œä¸­æ–­ï¼Œç›´æ¥é‡æ–°è¿è¡Œè„šæœ¬å³å¯ç»­ä¼ 
  - ä¸éœ€è¦ä»»ä½•å‚æ•°ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶ç»§ç»­ä¸‹è½½
  - ä¸ä¼šé‡å¤ä¸‹è½½ç©ºå­—èŠ‚ï¼Œè·å¾—æœ€ä½³æ•ˆç‡

ğŸ” ä»£ç†æ”¯æŒï¼š
  è‡ªåŠ¨æ£€æµ‹ç¯å¢ƒå˜é‡ï¼ˆHTTP_PROXY, HTTPS_PROXY, NO_PROXY ç­‰ï¼‰
  
  æ–¹å¼ 1: ä» /etc/network_turbo è¯»å–ï¼ˆAutoDL æ¨èï¼‰
    source /etc/network_turbo && python download_models.py
  
  æ–¹å¼ 2: ä¸»åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡
    export HTTP_PROXY=http://proxy:8080
    export HTTPS_PROXY=http://proxy:8080
    python download_models.py
  
  æ–¹å¼ 3: ä¸€è¡Œå‘½ä»¤
    HTTP_PROXY=http://proxy:8080 python download_models.py
"""

import argparse
import os
import sys
import urllib.request
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# ========== ä»£ç†é…ç½®æ”¯æŒ ==========
def setup_proxy_from_env():
    """
    ä»ç¯å¢ƒå˜é‡è¯»å–ä»£ç†è®¾ç½®ï¼ˆæ”¯æŒ HTTP_PROXY, HTTPS_PROXY, ALL_PROXY ç­‰ï¼‰
    ä¼˜å…ˆçº§: ALL_PROXY > HTTPS_PROXY/HTTP_PROXY > (no proxy)
    åŒæ—¶æ”¯æŒ no_proxy é…ç½®ï¼ˆè·³è¿‡ç‰¹å®šåŸŸåï¼‰
    """
    proxy_url = None
    no_proxy = os.environ.get('no_proxy') or os.environ.get('NO_PROXY', '')
    
    # æ£€æŸ¥å„ç§å¸¸è§çš„ä»£ç†ç¯å¢ƒå˜é‡
    proxy_vars = ['ALL_PROXY', 'all_proxy', 'HTTPS_PROXY', 'https_proxy', 'HTTP_PROXY', 'http_proxy']
    
    for var in proxy_vars:
        if var in os.environ and os.environ[var]:
            proxy_url = os.environ[var]
            break
    
    if proxy_url:
        print_colored(f"âœ“ æ£€æµ‹åˆ°ä»£ç†é…ç½®: {proxy_url}", "blue")
        if no_proxy:
            print_colored(f"âœ“ no_proxy é…ç½®: {no_proxy}", "blue")
        
        # ä¸º urllib è®¾ç½®ä»£ç†
        proxy_handler = urllib.request.ProxyHandler({
            'http': proxy_url,
            'https': proxy_url
        })
        opener = urllib.request.build_opener(proxy_handler)
        urllib.request.install_opener(opener)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡ä¾›ç¬¬ä¸‰æ–¹åº“ä½¿ç”¨
        os.environ['HTTP_PROXY'] = proxy_url
        os.environ['HTTPS_PROXY'] = proxy_url
        if no_proxy:
            os.environ['no_proxy'] = no_proxy
            os.environ['NO_PROXY'] = no_proxy
        
        return True
    
    return False


# å¯ç”¨çš„æ¨¡å‹é…ç½®
# source: ModelScope æˆ– HuggingFace
MODELS = {
    "2.0": {
        "source": "modelscope",
        "id": "iic/CosyVoice2-0.5B",
        "dir": "pretrained_models/CosyVoice2-0.5B",
        "description": "CosyVoice 2.0 (æ¨è, ModelScope)",
        "size": "~2.5GB"
    },
    "2.0-llm": {
        "source": "modelscope",
        "id": "yunye007/cosyvoice2_llm",
        "dir": "pretrained_models/cosyvoice2_llm",
        "description": "CosyVoice 2.0 LLM (ModelScope)",
        "size": "~2.5GB"
    },
    "300m": {
        "source": "modelscope",
        "id": "iic/CosyVoice-300M",
        "dir": "pretrained_models/CosyVoice-300M",
        "description": "CosyVoice-300M åŸºç¡€æ¨¡å‹",
        "size": "~1.5GB"
    },
    "300m-sft": {
        "source": "modelscope",
        "id": "iic/CosyVoice-300M-SFT",
        "dir": "pretrained_models/CosyVoice-300M-SFT",
        "description": "CosyVoice-300M SFT ç‰ˆæœ¬",
        "size": "~1.5GB"
    },
    "300m-instruct": {
        "source": "modelscope",
        "id": "iic/CosyVoice-300M-Instruct",
        "dir": "pretrained_models/CosyVoice-300M-Instruct",
        "description": "CosyVoice-300M Instruct ç‰ˆæœ¬",
        "size": "~1.5GB"
    },
    "ttsfrd": {
        "source": "modelscope",
        "id": "iic/CosyVoice-ttsfrd",
        "dir": "pretrained_models/CosyVoice-ttsfrd",
        "description": "æ–‡æœ¬è§„èŒƒåŒ–èµ„æºï¼ˆå¯é€‰ï¼‰",
        "size": "~100MB"
    }
}


def print_colored(text, color="green"):
    """æ‰“å°å¸¦é¢œè‰²çš„æ–‡æœ¬"""
    colors = {
        "green": "\033[0;32m",
        "yellow": "\033[1;33m",
        "red": "\033[0;31m",
        "blue": "\033[0;34m",
        "reset": "\033[0m"
    }
    print(f"{colors.get(color, '')}{text}{colors['reset']}")


def list_models():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
    print("\nå¯ç”¨çš„æ¨¡å‹:")
    print("=" * 80)
    for key, model in MODELS.items():
        status = "âœ… å·²ä¸‹è½½" if os.path.exists(model["dir"]) else "â¬‡ï¸  æœªä¸‹è½½"
        source = model['source'].upper()
        print(f"{key:15} {status:10} [{source:11}] {model['description']:35} ({model['size']})")
    print("=" * 80)
    print("\nä½¿ç”¨ç¤ºä¾‹:")
    print("  python download_models.py --model 2.0              # ä¸‹è½½ CosyVoice 2.0 (ModelScope)")
    print("  python download_models.py --model 2.0-llm          # ä¸‹è½½ CosyVoice 2.0 LLM (HuggingFace)")
    print("  python download_models.py                          # ä¸‹è½½æ¨èæ¨¡å‹ (2.0, 2.0-llm, tts)")
    print()


def check_model_exists(model_dir):
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å®Œå…¨ä¸‹è½½"""
    return os.path.exists(model_dir) and os.path.isdir(model_dir) and len(os.listdir(model_dir)) > 0


def is_model_incomplete(model_dir):
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¸‹è½½ä¸å®Œæ•´ï¼ˆç”¨äºç»­ä¼ è¯†åˆ«ï¼‰"""
    if not os.path.exists(model_dir):
        return False
    # å¦‚æœç›®å½•å­˜åœ¨ä½†ä¸ºç©ºï¼Œè¡¨ç¤ºä¸‹è½½ä¸å®Œæ•´
    if os.path.isdir(model_dir) and len(os.listdir(model_dir)) == 0:
        return True
    # å¦‚æœå­˜åœ¨ .incomplete æˆ–ç±»ä¼¼æ ‡è®°æ–‡ä»¶ï¼Œè¡¨ç¤ºä¸‹è½½ä¸å®Œæ•´
    # é€šå¸¸æ¡†æ¶ä¼šè‡ªåŠ¨å¤„ç†ï¼Œè¿™é‡Œåªåšç®€å•æ£€æŸ¥
    return False


def download_model_from_modelscope(model_id, model_dir, description):
    """ä» ModelScope ä¸‹è½½æ¨¡å‹ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼  + å¤šçº¿ç¨‹åŠ é€Ÿï¼‰"""
    try:
        from modelscope import snapshot_download
        
        print("   æ­£åœ¨ä» ModelScope ä¸‹è½½... è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ")
        print("   ğŸ’¡ æ”¯æŒæ–­ç‚¹ç»­ä¼ : ç½‘ç»œä¸­æ–­åå¯é‡æ–°è¿è¡Œè„šæœ¬ç»§ç»­ä¸‹è½½")
        print("   ğŸš€ ä½¿ç”¨ 6 çº¿ç¨‹å¹¶å‘ä¸‹è½½ï¼Œé…åˆå¤šæ¨¡å‹å¹¶è¡Œæœ€å¤§åŒ–å¸¦å®½")
        if 'HTTP_PROXY' in os.environ or 'HTTPS_PROXY' in os.environ:
            print("   ğŸ” ä½¿ç”¨ä»£ç†é…ç½®è¿æ¥")
        
        # ModelScope çš„ snapshot_download æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œå¤šçº¿ç¨‹ä¸‹è½½
        # max_workers å‚æ•°æ§åˆ¶å¹¶å‘ä¸‹è½½çº¿ç¨‹æ•°ï¼Œå»ºè®® 4-8 ä¸ªçº¿ç¨‹
        snapshot_download(
            model_id, 
            local_dir=model_dir,
            max_workers=6  # ä½¿ç”¨ 6 ä¸ªçº¿ç¨‹å¹¶å‘ä¸‹è½½ï¼Œé…åˆå¤šæ¨¡å‹å¹¶è¡Œ
        )
        
        print_colored(f"âœ… ä¸‹è½½å®Œæˆ: {description}", "green")
        return True
        
    except ImportError:
        print_colored("âŒ é”™è¯¯: æœªæ‰¾åˆ° modelscope æ¨¡å—", "red")
        print("   è¯·ç¡®ä¿å·²å®‰è£…: uv pip install modelscope")
        return False
        
    except Exception as e:
        print_colored(f"âŒ ä¸‹è½½å¤±è´¥: {e}", "red")
        print("\nå»ºè®®:")
        print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä»£ç†é…ç½®")
        print("  2. ç½‘ç»œæ¢å¤åé‡æ–°è¿è¡Œè„šæœ¬ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ :")
        print(f"     python download_models.py --model {model_id.split('/')[-1]}")
        print("  3. æˆ–ä½¿ç”¨ git æ–¹å¼ä¸‹è½½:")
        print(f"     git clone https://www.modelscope.cn/{model_id}.git {model_dir}")
        return False


def download_model_from_huggingface(model_id, model_dir, description):
    """ä» HuggingFace ä¸‹è½½æ¨¡å‹ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼  + å¤šçº¿ç¨‹åŠ é€Ÿï¼‰"""
    try:
        from huggingface_hub import snapshot_download as hf_snapshot_download
        
        print("   æ­£åœ¨ä» HuggingFace ä¸‹è½½... è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ")
        print("   ğŸ’¡ æ”¯æŒæ–­ç‚¹ç»­ä¼ : ç½‘ç»œä¸­æ–­åå¯é‡æ–°è¿è¡Œè„šæœ¬ç»§ç»­ä¸‹è½½")
        print("   ğŸš€ ä½¿ç”¨ 6 çº¿ç¨‹å¹¶å‘ä¸‹è½½ï¼Œé…åˆå¤šæ¨¡å‹å¹¶è¡Œæœ€å¤§åŒ–å¸¦å®½")
        if 'HTTP_PROXY' in os.environ or 'HTTPS_PROXY' in os.environ:
            print("   ğŸ” ä½¿ç”¨ä»£ç†é…ç½®è¿æ¥")
        
        # HuggingFace çš„ snapshot_download æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œå¤šçº¿ç¨‹ä¸‹è½½
        # max_workers å‚æ•°æ§åˆ¶å¹¶å‘ä¸‹è½½çº¿ç¨‹æ•°
        hf_snapshot_download(
            repo_id=model_id, 
            local_dir=model_dir,
            max_workers=6  # ä½¿ç”¨ 6 ä¸ªçº¿ç¨‹å¹¶å‘ä¸‹è½½ï¼Œé…åˆå¤šæ¨¡å‹å¹¶è¡Œ
        )
        
        print_colored(f"âœ… ä¸‹è½½å®Œæˆ: {description}", "green")
        return True
        
    except ImportError:
        print_colored("âŒ é”™è¯¯: æœªæ‰¾åˆ° huggingface_hub æ¨¡å—", "red")
        print("   è¯·ç¡®ä¿å·²å®‰è£…: uv pip install huggingface-hub")
        print("\næˆ–ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·:")
        print("   huggingface-cli download --local-dir {model_dir} {model_id}")
        return False
        
    except Exception as e:
        print_colored(f"âŒ ä¸‹è½½å¤±è´¥: {e}", "red")
        print("\nå»ºè®®:")
        print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä»£ç†é…ç½®")
        print("  2. ç½‘ç»œæ¢å¤åé‡æ–°è¿è¡Œè„šæœ¬ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ :")
        print(f"     python download_models.py")
        print("  3. æˆ–ä½¿ç”¨ huggingface-cli å‘½ä»¤ï¼ˆä¹Ÿæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰:")
        print(f"     huggingface-cli download --local-dir {model_dir} {model_id}")
        return False


def download_model(model_id, model_dir, description, source="modelscope"):
    """ä¸‹è½½å•ä¸ªæ¨¡å‹"""
    if check_model_exists(model_dir):
        print_colored(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {description} ({model_dir})", "yellow")
        return True
    
    print_colored(f"\nâ¬‡ï¸  å¼€å§‹ä¸‹è½½: {description}", "blue")
    print(f"   æ¥æº: {source.upper()}")
    print(f"   æ¨¡å‹ ID: {model_id}")
    print(f"   ä¿å­˜è·¯å¾„: {model_dir}")
    
    if source == "huggingface":
        return download_model_from_huggingface(model_id, model_dir, description)
    else:
        return download_model_from_modelscope(model_id, model_dir, description)


def main():
    """ä¸»å‡½æ•°"""
    # ä¸è¦ç¼ºå¤± âœ…
    # ä¸ºäº†æ”¯æŒä»£ç†é…ç½®ï¼Œåº”è¯¥æœ«å°¾æ‰§è¡Œè„šæœ¬æ—¶å·²ç»é’ˆå¯¹äº†ä»£ç†
    # ä½†ä¸ºäº†ä¿é™©èµ·è§‘ï¼Œä¹Ÿåœ¨è¿™é‡Œæ‰§è¡Œä¸€æ¬¡
    setup_proxy_from_env()
    
    parser = argparse.ArgumentParser(
        description="CosyVoice æ¨¡å‹ä¸‹è½½å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python download_models.py                    # ä¸‹è½½æ¨èæ¨¡å‹ (2.0, 2.0-llm, tts)
  python download_models.py --model 2.0        # ä»…ä¸‹è½½ CosyVoice 2.0 (ModelScope)
  python download_models.py --model 2.0-llm    # ä»…ä¸‹è½½ CosyVoice 2.0 LLM (HuggingFace)
  python download_models.py --model 300m       # ä»…ä¸‹è½½ CosyVoice-300M
  python download_models.py --list             # åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹
  python download_models.py --all              # ä¸‹è½½æ‰€æœ‰æ¨¡å‹
  python download_models.py --force            # å¼ºåˆ¶é‡æ–°ä¸‹è½½å·²å­˜åœ¨çš„æ¨¡å‹
        """
    )
    
    parser.add_argument(
        "--model",
        choices=list(MODELS.keys()),
        help="æŒ‡å®šè¦ä¸‹è½½çš„æ¨¡å‹ï¼ˆå¦‚: 2.0, 2.0-hf, 300m ç­‰ï¼‰"
    )
    
    parser.add_argument(
        "--list",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"
    )
    
    parser.add_argument(
        "--all",
        action="store_true",
        help="ä¸‹è½½æ‰€æœ‰æ¨¡å‹ï¼ˆä¸æŒ‡å®š --model æ—¶é»˜è®¤ä»…ä¸‹è½½æ¨èæ¨¡å‹ï¼‰"
    )
    
    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°ä¸‹è½½å·²å­˜åœ¨çš„æ¨¡å‹"
    )
    
    args = parser.parse_args()
    
    # åˆ—å‡ºæ¨¡å‹
    if args.list:
        list_models()
        return 0
    
    print_colored("\nğŸ¤ CosyVoice æ¨¡å‹ä¸‹è½½å·¥å…· (æ”¯æŒ ModelScope & HuggingFace)\n", "blue")
    
    # ç¡®å®šè¦ä¸‹è½½çš„æ¨¡å‹
    if args.model:
        # æŒ‡å®šå…·ä½“æ¨¡å‹
        models_to_download = {args.model: MODELS[args.model]}
    elif args.all:
        # ä¸‹è½½æ‰€æœ‰æ¨¡å‹
        models_to_download = MODELS.copy()
    else:
        # é»˜è®¤ä¸‹è½½æ¨èæ¨¡å‹ï¼š2.0, 2.0-llm, tts
        models_to_download = {
            "2.0": MODELS["2.0"],
            "2.0-llm": MODELS["2.0-llm"],
            "ttsfrd": MODELS["ttsfrd"]
        }
    
    # åˆ›å»ºæ¨¡å‹ç›®å½•
    os.makedirs("pretrained_models", exist_ok=True)
    
    # ä¸‹è½½æ¨¡å‹ï¼ˆå¹¶è¡Œä¸‹è½½å¤šä¸ªæ¨¡å‹ä»¥è·‘æ»¡å¸¦å®½ï¼‰
    success_count = 0
    total_count = len(models_to_download)
    
    print(f"è®¡åˆ’ä¸‹è½½ {total_count} ä¸ªæ¨¡å‹")
    print(f"ğŸš€ ä½¿ç”¨å¹¶è¡Œä¸‹è½½ç­–ç•¥ï¼ŒåŒæ—¶ä¸‹è½½æœ€å¤š 3 ä¸ªæ¨¡å‹ä»¥æœ€å¤§åŒ–å¸¦å®½åˆ©ç”¨\n")
    
    # é¢„å¤„ç†ï¼šæ¸…ç†å¼ºåˆ¶é‡æ–°ä¸‹è½½æˆ–ä¸å®Œæ•´çš„æ¨¡å‹
    import shutil
    for key, model in models_to_download.items():
        if args.force and check_model_exists(model["dir"]):
            print(f"ğŸ—‘ï¸  åˆ é™¤å·²å­˜åœ¨çš„æ¨¡å‹: {model['dir']}")
            shutil.rmtree(model["dir"])
        
        if is_model_incomplete(model["dir"]):
            print(f"âš ï¸  æ£€æµ‹åˆ°ä¸å®Œæ•´ä¸‹è½½: {model['dir']}ï¼ˆä¸ºç©ºç›®å½•ï¼Œå°†åˆ é™¤åé‡æ–°ä¸‹è½½ï¼‰")
            shutil.rmtree(model["dir"])
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œä¸‹è½½å¤šä¸ªæ¨¡å‹
    # max_workers=3 è¡¨ç¤ºæœ€å¤šåŒæ—¶ä¸‹è½½ 3 ä¸ªæ¨¡å‹
    # æ¯ä¸ªæ¨¡å‹å†…éƒ¨è¿˜ä¼šä½¿ç”¨ 6 ä¸ªçº¿ç¨‹ä¸‹è½½æ–‡ä»¶ï¼Œæ€»å…±çº¦ 18 ä¸ªå¹¶å‘è¿æ¥
    with ThreadPoolExecutor(max_workers=3) as executor:
        # æäº¤æ‰€æœ‰ä¸‹è½½ä»»åŠ¡
        future_to_model = {
            executor.submit(
                download_model, 
                model["id"], 
                model["dir"], 
                model["description"], 
                model["source"]
            ): key
            for key, model in models_to_download.items()
        }
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶ç»Ÿè®¡ç»“æœ
        for future in as_completed(future_to_model):
            key = future_to_model[future]
            try:
                if future.result():
                    success_count += 1
            except Exception as e:
                print_colored(f"âŒ æ¨¡å‹ {key} ä¸‹è½½æ—¶å‘ç”Ÿå¼‚å¸¸: {e}", "red")
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print(f"ä¸‹è½½å®Œæˆ: {success_count}/{total_count} ä¸ªæ¨¡å‹ä¸‹è½½æˆåŠŸ")
    print("=" * 70)
    
    if success_count == total_count:
        print_colored("\nâœ… æ‰€æœ‰æ¨¡å‹ä¸‹è½½æˆåŠŸï¼", "green")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. è¿è¡Œå®‰è£…éªŒè¯:")
        print("     uv run python test_installation.py")
        print("\n  2. å¯åŠ¨ Web ç•Œé¢:")
        print("     uv run python webui.py --port 50000 --model_dir pretrained_models/CosyVoice2-0.5B")
        print("\nğŸ’¡ ç¦»çº¿ç»­ä¼ : å¦‚ä¸‹è½½å¤±è´¥ï¼Œç½‘ç»œæ¢å¤åç›´æ¥é‡æ–°è¿è¡Œè„šæœ¬å³å¯ç»­ä¼ ä¸‹è½½")
        return 0
    else:
        print_colored(f"\nâš ï¸  éƒ¨åˆ†æ¨¡å‹ä¸‹è½½å¤±è´¥ ({total_count - success_count} ä¸ª)", "yellow")
        print("\nå»ºè®®:")
        print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("  2. ä½¿ç”¨ git æ–¹å¼ä¸‹è½½å¤±è´¥çš„æ¨¡å‹")
        print("  3. æŸ¥çœ‹ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        return 1


if __name__ == "__main__":
    # é¦–å…ˆä»ç¯å¢ƒå˜é‡è¯»å–ä»£ç†é…ç½®ï¼ˆå¹¶è®¾ç½®ç»™å„ä¸ªä¸‹è½½åº“ï¼‰
    print("\n" + "="*70)
    print("ğŸš€ CosyVoice æ¨¡å‹ä¸‹è½½å™¨")
    print("="*70)
    
    has_proxy = setup_proxy_from_env()
    if not has_proxy:
        print("â„¹ï¸  æœªæ£€æµ‹åˆ°ä»£ç†é…ç½®ï¼Œç›´æ¥è¿æ¥ç½‘ç»œ")
    
    print()
    sys.exit(main())
